{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 972,
     "output_extras": [
      {
       "item_id": 24
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24051,
     "status": "ok",
     "timestamp": 1522812503685,
     "user": {
      "displayName": "Chen Zeng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "104203797268465593050"
     },
     "user_tz": 300
    },
    "id": "0vOpX9SstEZE",
    "outputId": "2a863fb2-c490-45ef-9d2d-8f7beec6ad48"
   },
   "outputs": [],
   "source": [
    "# This work is inspired by https://github.com/matterport/Mask_RCNN\n",
    "\n",
    "# Data download and unzipping\n",
    "!wget https://raw.githubusercontent.com/AakashSudhakar/2018-data-science-bowl/master/compressed_files/stage1_test.zip -c\n",
    "!wget https://raw.githubusercontent.com/AakashSudhakar/2018-data-science-bowl/master/compressed_files/stage1_train.zip -c\n",
    "# !wget https://raw.githubusercontent.com/ZengChen94/Kaggle-Dataset/master/stage1_test.zip -c\n",
    "# !wget https://raw.githubusercontent.com/ZengChen94/Kaggle-Dataset/master/stage1_train.zip -c\n",
    "!mkdir stage1_train stage1_test\n",
    "!unzip -q stage1_train.zip -d stage1_train/\n",
    "!unzip -q stage1_test.zip -d stage1_test/\n",
    "\n",
    "# Downloading and intstalling keras\n",
    "!pip install keras\n",
    "!pip install tqdm\n",
    "!pip install imgaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 221,
     "output_extras": [
      {
       "item_id": 14
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10268,
     "status": "ok",
     "timestamp": 1522812513992,
     "user": {
      "displayName": "Chen Zeng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "104203797268465593050"
     },
     "user_tz": 300
    },
    "id": "-DcooUSd07xo",
    "outputId": "e067797e-6ec0-4f05-b37b-15427b066354"
   },
   "outputs": [],
   "source": [
    "# Downloading the library Mask_RCNN\n",
    "!git clone https://github.com/matterport/Mask_RCNN.git\n",
    "# !git clone https://github.com/ZengChen94/Mask_RCNN.git\n",
    "!mv -r ./Mask_RCNN/* ./\n",
    "!rm -r ./Mask_RCNN\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3UOMvOZatxTr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 68,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 3
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11800,
     "status": "ok",
     "timestamp": 1522812526328,
     "user": {
      "displayName": "Chen Zeng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "104203797268465593050"
     },
     "user_tz": 300
    },
    "id": "it1OXYJjtEZL",
    "outputId": "97bb4712-e48b-4c22-9f49-cdb63f85d823"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "# import utils\n",
    "import cv2\n",
    "from glob import glob\n",
    "import skimage.io\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.patches as patches\n",
    "# from config import Config\n",
    "# import model as modellib\n",
    "# import visualize\n",
    "# from model import log\n",
    "import imgaug\n",
    "import warnings\n",
    "\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "ROOT_DIR = os.getcwd()\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "TRAIN_PATH = './stage1_train/'\n",
    "TEST_PATH = './stage2_test/'\n",
    "train_ids = next(os.walk(TRAIN_PATH))[1]\n",
    "test_ids = next(os.walk(TEST_PATH))[1]\n",
    "kernel = np.ones((1,1),np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "oXqSwLVctEZj"
   },
   "outputs": [],
   "source": [
    "class KaggleTrainDataset(utils.Dataset):\n",
    "    def get_path(self, id_):\n",
    "        return './stage1_train/' + id_ + '/images/' + id_ + '.png'\n",
    "    \n",
    "    def load_data(self, train_ids):\n",
    "        self.add_class(\"nuclei\", 1, \"nuclei\")\n",
    "        self.sizes = []\n",
    "        self.img_ids = train_ids\n",
    "        for i, id_ in tqdm(enumerate(self.img_ids), total=len(self.img_ids)):\n",
    "            path = self.get_path(id_)\n",
    "            img = imread(path)\n",
    "            if (len(img.shape) == 2):\n",
    "                img2 = np.zeros((img.shape[0], img.shape[1], 3))\n",
    "                img2[:,:,0] = img\n",
    "                img2[:,:,1] = img\n",
    "                img2[:,:,2] = img\n",
    "                img = img2\n",
    "            img = img[:, :, :3]\n",
    "            img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "            w, h = img.shape[0], img.shape[1]\n",
    "            self.sizes.append((w, h))\n",
    "            self.add_image(\"nuclei\", image_id = i, path=id_, width=w, height=h)\n",
    "\n",
    "    def load_image(self, image_id):\n",
    "        image_name = self.img_ids[image_id]\n",
    "        path = self.get_path(image_name)\n",
    "        img = imread(path)\n",
    "        if (len(img.shape) == 2):\n",
    "            img2 = np.zeros((img.shape[0], img.shape[1], 3))\n",
    "            img2[:,:,0] = img\n",
    "            img2[:,:,1] = img\n",
    "            img2[:,:,2] = img\n",
    "            img = img2\n",
    "        img = img[:, :, :3]\n",
    "        w, h = img.shape[0], img.shape[1]\n",
    "        return img\n",
    "    \n",
    "    def load_mask(self, image_id):\n",
    "        id_ = self.img_ids[image_id]\n",
    "        mask_path = './stage1_train/' + id_ + '/masks/'\n",
    "        num_masks = len(next(os.walk(mask_path))[2])\n",
    "        width, height = self.sizes[image_id]\n",
    "        mask = np.zeros((width, height, num_masks), dtype=np.bool)\n",
    "        for i, mask_file in enumerate(next(os.walk(mask_path))[2]):\n",
    "            mask_ = imread(mask_path + mask_file)\n",
    "            mask_ = mask_.reshape((mask_.shape[0], mask_.shape[1], 1))\n",
    "            mask[:,:,i:i+1] = mask_\n",
    "        return mask, np.ones(num_masks, np.int32)\n",
    "      \n",
    "class KaggleTestDataset(utils.Dataset):\n",
    "    def get_path(self, id_):\n",
    "        return './stage2_test/' + id_ + '/images/' + id_ + '.png'\n",
    "    \n",
    "    def load_data(self, test_ids):\n",
    "        self.add_class(\"nuclei\", 1, \"nuclei\")\n",
    "        self.sizes = []\n",
    "        self.img_ids = test_ids\n",
    "        for i, id_ in tqdm(enumerate(self.img_ids), total=len(self.img_ids)):\n",
    "            path = self.get_path(id_)\n",
    "            img = imread(path)\n",
    "            if (len(img.shape) == 2):\n",
    "                img2 = np.zeros((img.shape[0], img.shape[1], 3))\n",
    "                img2[:,:,0] = img\n",
    "                img2[:,:,1] = img\n",
    "                img2[:,:,2] = img\n",
    "                img = img2\n",
    "            img = img[:, :, :3]\n",
    "            img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "            w, h = img.shape[0], img.shape[1]\n",
    "            self.sizes.append((w, h))\n",
    "            self.add_image(\"nuclei\", image_id = i, path=id_, width=w, height=h)\n",
    "\n",
    "    def load_image(self, image_id):\n",
    "        image_name = self.img_ids[image_id]\n",
    "        path = self.get_path(image_name)\n",
    "        img = imread(path)\n",
    "        if (len(img.shape) == 2):\n",
    "            img2 = np.zeros((img.shape[0], img.shape[1], 3))\n",
    "            img2[:,:,0] = img\n",
    "            img2[:,:,1] = img\n",
    "            img2[:,:,2] = img\n",
    "            img = img2\n",
    "        img = img[:, :, :3]\n",
    "        w, h = img.shape[0], img.shape[1]\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 68,
     "output_extras": [
      {
       "item_id": 22
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5497,
     "status": "ok",
     "timestamp": 1522812532482,
     "user": {
      "displayName": "Chen Zeng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "104203797268465593050"
     },
     "user_tz": 300
    },
    "id": "Z2CnoFbptEZl",
    "outputId": "52ea8811-d52d-4e91-e766-11b2db67997e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:05<00:00, 110.68it/s]\n",
      "100%|██████████| 64/64 [00:00<00:00, 110.38it/s]\n",
      "100%|██████████| 3019/3019 [00:25<00:00, 117.83it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset_train = KaggleTrainDataset()\n",
    "dataset_train.load_data(train_ids[:600])\n",
    "# dataset_train.load_data(train_ids[:1000])\n",
    "dataset_train.prepare()\n",
    "\n",
    "dataset_val = KaggleTrainDataset()\n",
    "dataset_val.load_data(train_ids[600:664])\n",
    "dataset_val.prepare()\n",
    "\n",
    "dataset_test = KaggleTestDataset()\n",
    "dataset_test.load_data(test_ids)\n",
    "dataset_test.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 850,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 207,
     "status": "ok",
     "timestamp": 1522812532728,
     "user": {
      "displayName": "Chen Zeng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "104203797268465593050"
     },
     "user_tz": 300
    },
    "id": "O6F4c9UTtEZw",
    "outputId": "60bcd31d-59bd-4fdb-e2ba-ea3e1777f184"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet50\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     6\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "DETECTION_MAX_INSTANCES        400\n",
      "DETECTION_MIN_CONFIDENCE       0\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 6\n",
      "IMAGE_MAX_DIM                  512\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  512\n",
      "IMAGE_MIN_SCALE                2.0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [512 512   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               200\n",
      "MEAN_PIXEL                     [43.53 39.56 48.22]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           shapes\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.9\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    64\n",
      "STEPS_PER_EPOCH                100\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           128\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               100\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configurations\n",
    "class KaggleConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy shapes dataset.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the toy shapes dataset.\n",
    "    \"\"\"\n",
    "    NAME = \"shapes\"\n",
    "    \n",
    "#     GPU_COUNT = 1\n",
    "#     IMAGES_PER_GPU = 8\n",
    "#     NUM_CLASSES = 1 + 1\n",
    "#     IMAGE_MIN_DIM = 512\n",
    "#     IMAGE_MAX_DIM = 512\n",
    "#     RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  \n",
    "#     TRAIN_ROIS_PER_IMAGE = 32\n",
    "#     STEPS_PER_EPOCH = 100\n",
    "#     VALIDATION_STEPS = 5\n",
    "\n",
    "    IMAGES_PER_GPU = 6\n",
    "    NUM_CLASSES = 1 + 1  # Background + nucleus\n",
    "    IMAGE_MIN_DIM = 512\n",
    "    IMAGE_MAX_DIM = 512\n",
    "    IMAGE_MIN_SCALE = 2.0\n",
    "    \n",
    "    STEPS_PER_EPOCH = 100\n",
    "    VALIDATION_STEPS = 100\n",
    "\n",
    "    DETECTION_MIN_CONFIDENCE = 0\n",
    "    BACKBONE = \"resnet50\"\n",
    "    \n",
    "    RPN_NMS_THRESHOLD = 0.9\n",
    "    RPN_TRAIN_ANCHORS_PER_IMAGE = 64\n",
    "\n",
    "    MEAN_PIXEL = np.array([43.53, 39.56, 48.22])\n",
    "\n",
    "    USE_MINI_MASK = True\n",
    "    MINI_MASK_SHAPE = (56, 56)\n",
    "    TRAIN_ROIS_PER_IMAGE = 128\n",
    "    MAX_GT_INSTANCES = 200\n",
    "    DETECTION_MAX_INSTANCES = 400\n",
    "    \n",
    "config = KaggleConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "aBtTUhk2hpU6"
   },
   "outputs": [],
   "source": [
    "# Notebook Preferences\n",
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "9jMC4Al1hdpL"
   },
   "outputs": [],
   "source": [
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Weights to start with\n",
    "init_with = \"coco\"  # imagenet, coco, or last\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(model.find_last()[1], by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 8428,
     "output_extras": [
      {
       "item_id": 4
      },
      {
       "item_id": 6
      },
      {
       "item_id": 7
      },
      {
       "item_id": 8
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 159984,
     "status": "error",
     "timestamp": 1522811700220,
     "user": {
      "displayName": "Chen Zeng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "104203797268465593050"
     },
     "user_tz": 300
    },
    "id": "GfyPq_x8tEZ6",
    "outputId": "acd947a7-9d9f-4877-c619-998ea6ca37b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "\n",
      "Starting at epoch 58. LR=0.001\n",
      "\n",
      "Checkpoint Path: /home/ubuntu/kaggle-src/logs/shapes20180411T2031/mask_rcnn_shapes_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "WARNING:tensorflow:From /home/ubuntu/kaggle-src/mrcnn/model.py:2137: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/engine/training.py:2087: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 58. LR=0.001\n",
      "\n",
      "Checkpoint Path: /home/ubuntu/kaggle-src/logs/shapes20180411T2031/mask_rcnn_shapes_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "Epoch 59/60\n",
      " 99/100 [============================>.] - ETA: 4s - loss: 1.2408 - rpn_class_loss: 0.2588 - rpn_bbox_loss: 0.4587 - mrcnn_class_loss: 0.2280 - mrcnn_bbox_loss: 0.1061 - mrcnn_mask_loss: 0.1893"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/engine/training.py:2330: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 718s 7s/step - loss: 1.2362 - rpn_class_loss: 0.2569 - rpn_bbox_loss: 0.4560 - mrcnn_class_loss: 0.2279 - mrcnn_bbox_loss: 0.1062 - mrcnn_mask_loss: 0.1893 - val_loss: 0.9407 - val_rpn_class_loss: 0.0962 - val_rpn_bbox_loss: 0.2582 - val_mrcnn_class_loss: 0.2725 - val_mrcnn_bbox_loss: 0.1166 - val_mrcnn_mask_loss: 0.1972\n",
      "Epoch 60/60\n",
      "100/100 [==============================] - 552s 6s/step - loss: 0.8281 - rpn_class_loss: 0.0755 - rpn_bbox_loss: 0.2230 - mrcnn_class_loss: 0.2335 - mrcnn_bbox_loss: 0.1020 - mrcnn_mask_loss: 0.1941 - val_loss: 0.9372 - val_rpn_class_loss: 0.0846 - val_rpn_bbox_loss: 0.2315 - val_mrcnn_class_loss: 0.2767 - val_mrcnn_bbox_loss: 0.1304 - val_mrcnn_mask_loss: 0.2139\n"
     ]
    }
   ],
   "source": [
    "# # http://imgaug.readthedocs.io/en/latest/source/augmenters.html\n",
    "\n",
    "# augmentation = imgaug.augmenters.Fliplr(0.5)\n",
    "\n",
    "augmentation = imgaug.augmenters.SomeOf((0, 2), [\n",
    "        imgaug.augmenters.Fliplr(0.5),\n",
    "        imgaug.augmenters.Flipud(0.5),\n",
    "        imgaug.augmenters.OneOf([imgaug.augmenters.Affine(rotate=90),\n",
    "                   imgaug.augmenters.Affine(rotate=180),\n",
    "                   imgaug.augmenters.Affine(rotate=270)]),\n",
    "        imgaug.augmenters.Multiply((0.8, 1.5)),\n",
    "        imgaug.augmenters.GaussianBlur(sigma=(0.0, 5.0))\n",
    "    ])\n",
    "\n",
    "model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                epochs=20,\n",
    "                augmentation=augmentation,\n",
    "                layers='heads')\n",
    "\n",
    "model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                epochs=60,\n",
    "                augmentation=augmentation,\n",
    "                layers='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ESXDFFNTikNO"
   },
   "outputs": [],
   "source": [
    "# Save weights\n",
    "# Typically not needed because callbacks save after every epoch\n",
    "# Uncomment to save manually\n",
    "model_path = os.path.join(MODEL_DIR, \"mask_rcnn_shapes.h5\")\n",
    "model.keras_model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 231,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 426,
     "status": "error",
     "timestamp": 1522812194009,
     "user": {
      "displayName": "Chen Zeng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "104203797268465593050"
     },
     "user_tz": 300
    },
    "id": "crfmuM0BiVGr",
    "outputId": "37853fcd-cdba-4487-ca3f-6d9851eacd69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from  /home/ubuntu/kaggle-src/logs/shapes20180411T2031/mask_rcnn_shapes_0060.h5\n"
     ]
    }
   ],
   "source": [
    "# Detection\n",
    "class InferenceConfig(KaggleConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    RPN_NMS_THRESHOLD = 0.7\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "model_path = model.find_last()[1]\n",
    "# model_path = './logs/shapes20180411T2031/mask_rcnn_shapes_0060.h5'\n",
    "\n",
    "# Load trained weights (fill in path to trained weights here)\n",
    "assert model_path != \"\", \"Provide path to trained weights\"\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "GQosj2BUtEaF"
   },
   "outputs": [],
   "source": [
    "# # Test on a random image\n",
    "# image_id = random.choice(dataset_val.image_ids)\n",
    "\n",
    "# original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "#     modellib.load_image_gt(dataset_val, inference_config, \n",
    "#                            image_id, use_mini_mask=False)\n",
    "\n",
    "# # Ground truth\n",
    "# log(\"original_image\", original_image)\n",
    "# log(\"image_meta\", image_meta)\n",
    "# log(\"gt_class_id\", gt_class_id)\n",
    "# log(\"gt_bbox\", gt_bbox)\n",
    "# log(\"gt_mask\", gt_mask)\n",
    "\n",
    "# visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "#                             dataset_train.class_names, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "dkpUC7GttEaH"
   },
   "outputs": [],
   "source": [
    "# results = model.detect([original_image], verbose=1)\n",
    "\n",
    "# r = results[0]\n",
    "# visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "#                             dataset_val.class_names, r['scores'], ax=get_ax())\n",
    "\n",
    "# # r['masks'].shape = 256*256*num\n",
    "# # plt.imshow(r['masks'][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "yeV7kclMtEaK"
   },
   "outputs": [],
   "source": [
    "# # Compute VOC-Style mAP @ IoU=0.5\n",
    "# # Running on 10 images. Increase for better accuracy.\n",
    "# image_ids = np.random.choice(dataset_val.image_ids, 10)\n",
    "# APs = []\n",
    "# for image_id in image_ids:\n",
    "#     # Load image and ground truth data\n",
    "#     image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "#         modellib.load_image_gt(dataset_val, inference_config,\n",
    "#                                image_id, use_mini_mask=False)\n",
    "#     molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
    "#     # Run object detection\n",
    "#     results = model.detect([image], verbose=0)\n",
    "#     r = results[0]\n",
    "#     # Compute AP\n",
    "#     AP, precisions, recalls, overlaps =\\\n",
    "#         utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "#                          r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "#     APs.append(AP)\n",
    "    \n",
    "# print(\"mAP: \", np.mean(APs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "eFNidQPd7Vbu"
   },
   "outputs": [],
   "source": [
    "# rle\n",
    "# inspired by the discussion of kaggle\n",
    "def numpy2encoding_no_overlap2(predicts, img_id):\n",
    "    sum_predicts = np.sum(predicts, axis=2)\n",
    "    rows, cols = np.where(sum_predicts>=2)\n",
    "    \n",
    "    for i in zip(rows, cols):\n",
    "        instance_indicies = np.where(np.any(predicts[i[0],i[1],:]))[0]\n",
    "        highest = instance_indicies[0]\n",
    "        predicts[i[0],i[1],:] = predicts[i[0],i[1],:]*0\n",
    "        predicts[i[0],i[1],highest] = 1\n",
    "    \n",
    "    ImageId = []\n",
    "    EncodedPixels = []\n",
    "    for i in range(predicts.shape[2]): \n",
    "        rle = run_length_encoding(predicts[:,:,i])\n",
    "        if len(rle)>0:\n",
    "            ImageId.append(img_id)\n",
    "            EncodedPixels.append(rle)\n",
    "    if len(ImageId) == 0:\n",
    "        ImageId.append(img_id)\n",
    "        EncodedPixels.append('')\n",
    "    return ImageId, EncodedPixels\n",
    "\n",
    "def run_length_encoding(x):\n",
    "    dots = np.where(x.T.flatten() == 1)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b>prev+1): run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    run_lengths = ' '.join([str(r) for r in run_lengths])\n",
    "    return run_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 231,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 284,
     "status": "error",
     "timestamp": 1522812213464,
     "user": {
      "displayName": "Chen Zeng",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "104203797268465593050"
     },
     "user_tz": 300
    },
    "id": "a3-GcgAC7Wm6",
    "outputId": "17f51046-8162-4b53-b4ea-6925eae35ce3"
   },
   "outputs": [],
   "source": [
    "ImageId = []\n",
    "EncodedPixels = []\n",
    "\n",
    "for image_id in dataset_test.image_ids:\n",
    "    img_id = dataset_test.img_ids[image_id]\n",
    "    image = dataset_test.load_image(image_id)\n",
    "    results = model.detect([image], verbose=0)\n",
    "    r = results[0]\n",
    "#     idx = utils.non_max_suppression(r['rois'], r['scores'], 0.2)\n",
    "#     ImageId_batch, EncodedPixels_batch = numpy2encoding_no_overlap2(r['masks'][idx], img_id)\n",
    "    ImageId_batch, EncodedPixels_batch = numpy2encoding_no_overlap2(r['masks'], img_id)\n",
    "    ImageId += ImageId_batch\n",
    "    EncodedPixels += EncodedPixels_batch\n",
    "    \n",
    "saved_file = 'rcnn-410.csv'\n",
    "\n",
    "# Create submission DataFrame\n",
    "sub = pd.DataFrame()\n",
    "sub['ImageId'] = ImageId\n",
    "# sub['EncodedPixels'] = pd.Series(EncodedPixels).apply(lambda x: ''.join(str(y) for y in x))\n",
    "sub['EncodedPixels'] = EncodedPixels\n",
    "sub.to_csv(saved_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "mask_rcnn-2.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
