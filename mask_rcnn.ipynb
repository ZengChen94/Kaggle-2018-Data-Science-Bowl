{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mask_rcnn-2.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "0vOpX9SstEZE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 16
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "b3668a88-9c0b-493f-a635-ea4e8872c822",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522768714986,
          "user_tz": 300,
          "elapsed": 16834,
          "user": {
            "displayName": "Chen Zeng",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "104203797268465593050"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Data download and unzipping\n",
        "!wget https://raw.githubusercontent.com/AakashSudhakar/2018-data-science-bowl/master/compressed_files/stage1_test.zip -c\n",
        "!wget https://raw.githubusercontent.com/AakashSudhakar/2018-data-science-bowl/master/compressed_files/stage1_train.zip -c\n",
        "# !wget https://raw.githubusercontent.com/ZengChen94/Kaggle-Dataset/master/stage1_test.zip -c\n",
        "# !wget https://raw.githubusercontent.com/ZengChen94/Kaggle-Dataset/master/stage1_train.zip -c\n",
        "!mkdir stage1_train stage1_test\n",
        "!unzip -q stage1_train.zip -d stage1_train/\n",
        "!unzip -q stage1_test.zip -d stage1_test/\n",
        "\n",
        "# Downloading and intstalling keras\n",
        "!pip install keras\n",
        "!pip install tqdm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-04-03 15:18:17--  https://raw.githubusercontent.com/AakashSudhakar/2018-data-science-bowl/master/compressed_files/stage1_test.zip\r\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9545388 (9.1M) [application/zip]\n",
            "Saving to: ‘stage1_test.zip’\n",
            "\n",
            "stage1_test.zip     100%[===================>]   9.10M  17.6MB/s    in 0.5s    \n",
            "\n",
            "2018-04-03 15:18:18 (17.6 MB/s) - ‘stage1_test.zip’ saved [9545388/9545388]\n",
            "\n",
            "--2018-04-03 15:18:19--  https://raw.githubusercontent.com/AakashSudhakar/2018-data-science-bowl/master/compressed_files/stage1_train.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 82923446 (79M) [application/zip]\n",
            "Saving to: ‘stage1_train.zip’\n",
            "\n",
            "stage1_train.zip    100%[===================>]  79.08M  73.0MB/s    in 1.1s    \n",
            "\n",
            "2018-04-03 15:18:21 (73.0 MB/s) - ‘stage1_train.zip’ saved [82923446/82923446]\n",
            "\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras)\n",
            "Collecting tqdm\n",
            "  Downloading tqdm-4.20.0-py2.py3-none-any.whl (41kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 2.1MB/s \n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "Successfully installed tqdm-4.20.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-DcooUSd07xo",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 12
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0b9cc630-7ae7-4551-a372-fd2edc09a630",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522768725137,
          "user_tz": 300,
          "elapsed": 10120,
          "user": {
            "displayName": "Chen Zeng",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "104203797268465593050"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Downloading the library Mask_RCNN\n",
        "!git clone https://github.com/matterport/Mask_RCNN.git\n",
        "# !git clone https://github.com/ZengChen94/Mask_RCNN.git\n",
        "!mv ./Mask_RCNN/* ./\n",
        "!rm -r ./Mask_RCNN\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Mask_RCNN'...\n",
            "remote: Counting objects: 369, done.\u001b[K\n",
            "remote: Total 369 (delta 0), reused 0 (delta 0), pack-reused 369\u001b[K\n",
            "Receiving objects: 100% (369/369), 50.61 MiB | 26.77 MiB/s, done.\n",
            "Resolving deltas: 100% (208/208), done.\n",
            "assets\t    inspect_data.ipynb\t   README.md\t    stage1_train.zip\n",
            "coco.py     inspect_model.ipynb    samples\t    train_shapes.ipynb\n",
            "config.py   inspect_weights.ipynb  shapes.py\t    utils.py\n",
            "datalab     LICENSE\t\t   stage1_test\t    visualize.py\n",
            "demo.ipynb  model.py\t\t   stage1_test.zip\n",
            "images\t    parallel_model.py\t   stage1_train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3UOMvOZatxTr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "it1OXYJjtEZL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            },
            {
              "item_id": 3
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "98686f72-c999-47db-f8e3-81b5f1132093",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522768739203,
          "user_tz": 300,
          "elapsed": 13441,
          "user": {
            "displayName": "Chen Zeng",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "104203797268465593050"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from itertools import chain\n",
        "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
        "from skimage.transform import resize\n",
        "from skimage.morphology import label\n",
        "import utils\n",
        "import cv2\n",
        "from glob import glob\n",
        "import skimage.io\n",
        "import seaborn as sns\n",
        "import sys\n",
        "import math\n",
        "import re\n",
        "import time\n",
        "import matplotlib\n",
        "import matplotlib.patches as patches\n",
        "from config import Config\n",
        "import model as modellib\n",
        "import visualize\n",
        "from model import log\n",
        "\n",
        "ROOT_DIR = os.getcwd()\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "if not os.path.exists(COCO_MODEL_PATH):\n",
        "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
        "TRAIN_PATH = './stage1_train/'\n",
        "TEST_PATH = './stage1_test/'\n",
        "train_ids = next(os.walk(TRAIN_PATH))[1]\n",
        "test_ids = next(os.walk(TEST_PATH))[1]\n",
        "kernel = np.ones((1,1),np.uint8)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading pretrained model to /content/mask_rcnn_coco.h5 ...\n",
            "... done downloading pretrained model!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oXqSwLVctEZj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class KaggleTrainDataset(utils.Dataset):\n",
        "    def get_path(self, id_):\n",
        "        return './stage1_train/' + id_ + '/images/' + id_ + '.png'\n",
        "    \n",
        "    def load_data(self, train_ids):\n",
        "        self.add_class(\"nuclei\", 1, \"nuclei\")\n",
        "        self.sizes = []\n",
        "        self.img_ids = train_ids\n",
        "        for i, id_ in tqdm(enumerate(self.img_ids), total=len(self.img_ids)):\n",
        "            path = self.get_path(id_)\n",
        "            img = imread(path)[:, :, :3]\n",
        "            img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
        "            w, h = img.shape[0], img.shape[1]\n",
        "            self.sizes.append((w, h))\n",
        "            self.add_image(\"nuclei\", image_id = i, path=id_, width=w, height=h)\n",
        "\n",
        "    def load_image(self, image_id):\n",
        "        image_name = self.img_ids[image_id]\n",
        "        path = self.get_path(image_name)\n",
        "        img = imread(path)[:,:,:3]\n",
        "        w, h = img.shape[0], img.shape[1]\n",
        "        return img\n",
        "    \n",
        "    def load_mask(self, image_id):\n",
        "        id_ = self.img_ids[image_id]\n",
        "        mask_path = './stage1_train/' + id_ + '/masks/'\n",
        "        num_masks = len(next(os.walk(mask_path))[2])\n",
        "        width, height = self.sizes[image_id]\n",
        "        mask = np.zeros((width, height, num_masks), dtype=np.bool)\n",
        "        for i, mask_file in enumerate(next(os.walk(mask_path))[2]):\n",
        "            mask_ = imread(mask_path + mask_file)\n",
        "            mask_ = mask_.reshape((mask_.shape[0], mask_.shape[1], 1))\n",
        "            mask[:,:,i:i+1] = mask_\n",
        "        return mask, np.ones(num_masks, np.int32)\n",
        "      \n",
        "class KaggleTestDataset(utils.Dataset):\n",
        "    def get_path(self, id_):\n",
        "        return './stage1_test/' + id_ + '/images/' + id_ + '.png'\n",
        "    \n",
        "    def load_data(self, test_ids):\n",
        "        self.add_class(\"nuclei\", 1, \"nuclei\")\n",
        "        self.sizes = []\n",
        "        self.img_ids = test_ids\n",
        "        for i, id_ in tqdm(enumerate(self.img_ids), total=len(self.img_ids)):\n",
        "            path = self.get_path(id_)\n",
        "            img = imread(path)[:, :, :3]\n",
        "            img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
        "            w, h = img.shape[0], img.shape[1]\n",
        "            self.sizes.append((w, h))\n",
        "            self.add_image(\"nuclei\", image_id = i, path=id_, width=w, height=h)\n",
        "\n",
        "    def load_image(self, image_id):\n",
        "        image_name = self.img_ids[image_id]\n",
        "        path = self.get_path(image_name)\n",
        "        img = imread(path)[:,:,:3]\n",
        "        w, h = img.shape[0], img.shape[1]\n",
        "        return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z2CnoFbptEZl",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 21
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e0ce3eac-1000-4d78-e150-086b307236d8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522768744995,
          "user_tz": 300,
          "elapsed": 5301,
          "user": {
            "displayName": "Chen Zeng",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "104203797268465593050"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "dataset_train = KaggleTrainDataset()\n",
        "dataset_train.load_data(train_ids[:600])\n",
        "dataset_train.prepare()\n",
        "\n",
        "dataset_val = KaggleTrainDataset()\n",
        "# dataset_val.load_data(train_ids[600:670])\n",
        "dataset_val.load_data(train_ids[600:664])\n",
        "dataset_val.prepare()\n",
        "\n",
        "dataset_test = KaggleTestDataset()\n",
        "dataset_test.load_data(test_ids)\n",
        "dataset_test.prepare()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 600/600 [00:04<00:00, 141.28it/s]\n",
            "100%|██████████| 64/64 [00:00<00:00, 164.89it/s]\n",
            "100%|██████████| 65/65 [00:00<00:00, 131.77it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "O6F4c9UTtEZw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "outputId": "b92ffc76-e2ca-466c-f5dd-ee6fe9cc7b3e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522768745266,
          "user_tz": 300,
          "elapsed": 239,
          "user": {
            "displayName": "Chen Zeng",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "104203797268465593050"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Configurations\n",
        "class KaggleConfig(Config):\n",
        "    \"\"\"Configuration for training on the toy shapes dataset.\n",
        "    Derives from the base Config class and overrides values specific\n",
        "    to the toy shapes dataset.\n",
        "    \"\"\"\n",
        "    NAME = \"shapes\"\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 8\n",
        "    NUM_CLASSES = 1 + 1\n",
        "    IMAGE_MIN_DIM = 512\n",
        "    IMAGE_MAX_DIM = 512\n",
        "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  \n",
        "    TRAIN_ROIS_PER_IMAGE = 32\n",
        "    STEPS_PER_EPOCH = 100\n",
        "    VALIDATION_STEPS = 5\n",
        "config = KaggleConfig()\n",
        "config.display()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet101\n",
            "BACKBONE_SHAPES                [[128 128]\n",
            " [ 64  64]\n",
            " [ 32  32]\n",
            " [ 16  16]\n",
            " [  8   8]]\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     8\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "DETECTION_MAX_INSTANCES        100\n",
            "DETECTION_MIN_CONFIDENCE       0.7\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 8\n",
            "IMAGE_MAX_DIM                  512\n",
            "IMAGE_MIN_DIM                  512\n",
            "IMAGE_PADDING                  True\n",
            "IMAGE_SHAPE                    [512 512   3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               100\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           shapes\n",
            "NUM_CLASSES                    2\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
            "STEPS_PER_EPOCH                100\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           32\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               5\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aBtTUhk2hpU6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Notebook Preferences\n",
        "def get_ax(rows=1, cols=1, size=8):\n",
        "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
        "    return ax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9jMC4Al1hdpL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Create model in training mode\n",
        "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
        "                          model_dir=MODEL_DIR)\n",
        "\n",
        "# Weights to start with\n",
        "init_with = \"coco\"  # imagenet, coco, or last\n",
        "if init_with == \"imagenet\":\n",
        "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
        "elif init_with == \"coco\":\n",
        "    # Load weights trained on MS COCO, but skip layers that\n",
        "    # are different due to the different number of classes\n",
        "    # See README for instructions to download the COCO weights\n",
        "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
        "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
        "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "elif init_with == \"last\":\n",
        "    # Load the last model you trained and continue training\n",
        "    model.load_weights(model.find_last()[1], by_name=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AiIu86KVtEZz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# import warnings\n",
        "# warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "# # Train the head branches\n",
        "# # Passing layers=\"heads\" freezes all layers except the head\n",
        "# # layers. You can also pass a regular expression to select\n",
        "# # which layers to train by name pattern.\n",
        "# model.train(dataset_train, dataset_val, \n",
        "#             learning_rate=config.LEARNING_RATE, \n",
        "#             epochs=1, layers='heads')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GfyPq_x8tEZ6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            },
            {
              "item_id": 4
            },
            {
              "item_id": 6
            },
            {
              "item_id": 16
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 4576
        },
        "outputId": "74ed0351-4b0a-4a6c-ed3b-ea809d3858c2"
      },
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "!pip install imgaug\n",
        "import imgaug\n",
        "augmentation = imgaug.augmenters.Fliplr(0.5)\n",
        "# Create model in training mode\n",
        "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
        "                          model_dir=MODEL_DIR)\n",
        "model_path = model.find_last()[1]\n",
        "model.load_weights(model_path, by_name=True)\n",
        "\n",
        "# Fine tune all layers\n",
        "# Passing layers=\"all\" trains all layers. You can also \n",
        "# pass a regular expression to select which layers to\n",
        "# train by name pattern.\n",
        "model.train(dataset_train, dataset_val, \n",
        "            learning_rate=config.LEARNING_RATE / 10,\n",
        "            epochs=70, \n",
        "            layers=\"all\",\n",
        "            augmentation=augmentation)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[autoreload of httplib2 failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "ValueError: __init__() requires a code object with 0 free vars, not 1\n",
            "]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from imgaug)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug)\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from imgaug)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug)\n",
            "Requirement already satisfied: matplotlib>=1.3.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug)\n",
            "Requirement already satisfied: networkx>=1.8 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug)\n",
            "Requirement already satisfied: pillow>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.3.1->scikit-image>=0.11.0->imgaug)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.3.1->scikit-image>=0.11.0->imgaug)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.3.1->scikit-image>=0.11.0->imgaug)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.3.1->scikit-image>=0.11.0->imgaug)\n",
            "Requirement already satisfied: decorator>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=1.8->scikit-image>=0.11.0->imgaug)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=2.1.0->scikit-image>=0.11.0->imgaug)\n",
            "\n",
            "Starting at epoch 51. LR=0.0001\n",
            "\n",
            "Checkpoint Path: /content/logs/shapes20180403T1519/mask_rcnn_shapes_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "conv1                  (Conv2D)\n",
            "bn_conv1               (BatchNorm)\n",
            "res2a_branch2a         (Conv2D)\n",
            "bn2a_branch2a          (BatchNorm)\n",
            "res2a_branch2b         (Conv2D)\n",
            "bn2a_branch2b          (BatchNorm)\n",
            "res2a_branch2c         (Conv2D)\n",
            "res2a_branch1          (Conv2D)\n",
            "bn2a_branch2c          (BatchNorm)\n",
            "bn2a_branch1           (BatchNorm)\n",
            "res2b_branch2a         (Conv2D)\n",
            "bn2b_branch2a          (BatchNorm)\n",
            "res2b_branch2b         (Conv2D)\n",
            "bn2b_branch2b          (BatchNorm)\n",
            "res2b_branch2c         (Conv2D)\n",
            "bn2b_branch2c          (BatchNorm)\n",
            "res2c_branch2a         (Conv2D)\n",
            "bn2c_branch2a          (BatchNorm)\n",
            "res2c_branch2b         (Conv2D)\n",
            "bn2c_branch2b          (BatchNorm)\n",
            "res2c_branch2c         (Conv2D)\n",
            "bn2c_branch2c          (BatchNorm)\n",
            "res3a_branch2a         (Conv2D)\n",
            "bn3a_branch2a          (BatchNorm)\n",
            "res3a_branch2b         (Conv2D)\n",
            "bn3a_branch2b          (BatchNorm)\n",
            "res3a_branch2c         (Conv2D)\n",
            "res3a_branch1          (Conv2D)\n",
            "bn3a_branch2c          (BatchNorm)\n",
            "bn3a_branch1           (BatchNorm)\n",
            "res3b_branch2a         (Conv2D)\n",
            "bn3b_branch2a          (BatchNorm)\n",
            "res3b_branch2b         (Conv2D)\n",
            "bn3b_branch2b          (BatchNorm)\n",
            "res3b_branch2c         (Conv2D)\n",
            "bn3b_branch2c          (BatchNorm)\n",
            "res3c_branch2a         (Conv2D)\n",
            "bn3c_branch2a          (BatchNorm)\n",
            "res3c_branch2b         (Conv2D)\n",
            "bn3c_branch2b          (BatchNorm)\n",
            "res3c_branch2c         (Conv2D)\n",
            "bn3c_branch2c          (BatchNorm)\n",
            "res3d_branch2a         (Conv2D)\n",
            "bn3d_branch2a          (BatchNorm)\n",
            "res3d_branch2b         (Conv2D)\n",
            "bn3d_branch2b          (BatchNorm)\n",
            "res3d_branch2c         (Conv2D)\n",
            "bn3d_branch2c          (BatchNorm)\n",
            "res4a_branch2a         (Conv2D)\n",
            "bn4a_branch2a          (BatchNorm)\n",
            "res4a_branch2b         (Conv2D)\n",
            "bn4a_branch2b          (BatchNorm)\n",
            "res4a_branch2c         (Conv2D)\n",
            "res4a_branch1          (Conv2D)\n",
            "bn4a_branch2c          (BatchNorm)\n",
            "bn4a_branch1           (BatchNorm)\n",
            "res4b_branch2a         (Conv2D)\n",
            "bn4b_branch2a          (BatchNorm)\n",
            "res4b_branch2b         (Conv2D)\n",
            "bn4b_branch2b          (BatchNorm)\n",
            "res4b_branch2c         (Conv2D)\n",
            "bn4b_branch2c          (BatchNorm)\n",
            "res4c_branch2a         (Conv2D)\n",
            "bn4c_branch2a          (BatchNorm)\n",
            "res4c_branch2b         (Conv2D)\n",
            "bn4c_branch2b          (BatchNorm)\n",
            "res4c_branch2c         (Conv2D)\n",
            "bn4c_branch2c          (BatchNorm)\n",
            "res4d_branch2a         (Conv2D)\n",
            "bn4d_branch2a          (BatchNorm)\n",
            "res4d_branch2b         (Conv2D)\n",
            "bn4d_branch2b          (BatchNorm)\n",
            "res4d_branch2c         (Conv2D)\n",
            "bn4d_branch2c          (BatchNorm)\n",
            "res4e_branch2a         (Conv2D)\n",
            "bn4e_branch2a          (BatchNorm)\n",
            "res4e_branch2b         (Conv2D)\n",
            "bn4e_branch2b          (BatchNorm)\n",
            "res4e_branch2c         (Conv2D)\n",
            "bn4e_branch2c          (BatchNorm)\n",
            "res4f_branch2a         (Conv2D)\n",
            "bn4f_branch2a          (BatchNorm)\n",
            "res4f_branch2b         (Conv2D)\n",
            "bn4f_branch2b          (BatchNorm)\n",
            "res4f_branch2c         (Conv2D)\n",
            "bn4f_branch2c          (BatchNorm)\n",
            "res4g_branch2a         (Conv2D)\n",
            "bn4g_branch2a          (BatchNorm)\n",
            "res4g_branch2b         (Conv2D)\n",
            "bn4g_branch2b          (BatchNorm)\n",
            "res4g_branch2c         (Conv2D)\n",
            "bn4g_branch2c          (BatchNorm)\n",
            "res4h_branch2a         (Conv2D)\n",
            "bn4h_branch2a          (BatchNorm)\n",
            "res4h_branch2b         (Conv2D)\n",
            "bn4h_branch2b          (BatchNorm)\n",
            "res4h_branch2c         (Conv2D)\n",
            "bn4h_branch2c          (BatchNorm)\n",
            "res4i_branch2a         (Conv2D)\n",
            "bn4i_branch2a          (BatchNorm)\n",
            "res4i_branch2b         (Conv2D)\n",
            "bn4i_branch2b          (BatchNorm)\n",
            "res4i_branch2c         (Conv2D)\n",
            "bn4i_branch2c          (BatchNorm)\n",
            "res4j_branch2a         (Conv2D)\n",
            "bn4j_branch2a          (BatchNorm)\n",
            "res4j_branch2b         (Conv2D)\n",
            "bn4j_branch2b          (BatchNorm)\n",
            "res4j_branch2c         (Conv2D)\n",
            "bn4j_branch2c          (BatchNorm)\n",
            "res4k_branch2a         (Conv2D)\n",
            "bn4k_branch2a          (BatchNorm)\n",
            "res4k_branch2b         (Conv2D)\n",
            "bn4k_branch2b          (BatchNorm)\n",
            "res4k_branch2c         (Conv2D)\n",
            "bn4k_branch2c          (BatchNorm)\n",
            "res4l_branch2a         (Conv2D)\n",
            "bn4l_branch2a          (BatchNorm)\n",
            "res4l_branch2b         (Conv2D)\n",
            "bn4l_branch2b          (BatchNorm)\n",
            "res4l_branch2c         (Conv2D)\n",
            "bn4l_branch2c          (BatchNorm)\n",
            "res4m_branch2a         (Conv2D)\n",
            "bn4m_branch2a          (BatchNorm)\n",
            "res4m_branch2b         (Conv2D)\n",
            "bn4m_branch2b          (BatchNorm)\n",
            "res4m_branch2c         (Conv2D)\n",
            "bn4m_branch2c          (BatchNorm)\n",
            "res4n_branch2a         (Conv2D)\n",
            "bn4n_branch2a          (BatchNorm)\n",
            "res4n_branch2b         (Conv2D)\n",
            "bn4n_branch2b          (BatchNorm)\n",
            "res4n_branch2c         (Conv2D)\n",
            "bn4n_branch2c          (BatchNorm)\n",
            "res4o_branch2a         (Conv2D)\n",
            "bn4o_branch2a          (BatchNorm)\n",
            "res4o_branch2b         (Conv2D)\n",
            "bn4o_branch2b          (BatchNorm)\n",
            "res4o_branch2c         (Conv2D)\n",
            "bn4o_branch2c          (BatchNorm)\n",
            "res4p_branch2a         (Conv2D)\n",
            "bn4p_branch2a          (BatchNorm)\n",
            "res4p_branch2b         (Conv2D)\n",
            "bn4p_branch2b          (BatchNorm)\n",
            "res4p_branch2c         (Conv2D)\n",
            "bn4p_branch2c          (BatchNorm)\n",
            "res4q_branch2a         (Conv2D)\n",
            "bn4q_branch2a          (BatchNorm)\n",
            "res4q_branch2b         (Conv2D)\n",
            "bn4q_branch2b          (BatchNorm)\n",
            "res4q_branch2c         (Conv2D)\n",
            "bn4q_branch2c          (BatchNorm)\n",
            "res4r_branch2a         (Conv2D)\n",
            "bn4r_branch2a          (BatchNorm)\n",
            "res4r_branch2b         (Conv2D)\n",
            "bn4r_branch2b          (BatchNorm)\n",
            "res4r_branch2c         (Conv2D)\n",
            "bn4r_branch2c          (BatchNorm)\n",
            "res4s_branch2a         (Conv2D)\n",
            "bn4s_branch2a          (BatchNorm)\n",
            "res4s_branch2b         (Conv2D)\n",
            "bn4s_branch2b          (BatchNorm)\n",
            "res4s_branch2c         (Conv2D)\n",
            "bn4s_branch2c          (BatchNorm)\n",
            "res4t_branch2a         (Conv2D)\n",
            "bn4t_branch2a          (BatchNorm)\n",
            "res4t_branch2b         (Conv2D)\n",
            "bn4t_branch2b          (BatchNorm)\n",
            "res4t_branch2c         (Conv2D)\n",
            "bn4t_branch2c          (BatchNorm)\n",
            "res4u_branch2a         (Conv2D)\n",
            "bn4u_branch2a          (BatchNorm)\n",
            "res4u_branch2b         (Conv2D)\n",
            "bn4u_branch2b          (BatchNorm)\n",
            "res4u_branch2c         (Conv2D)\n",
            "bn4u_branch2c          (BatchNorm)\n",
            "res4v_branch2a         (Conv2D)\n",
            "bn4v_branch2a          (BatchNorm)\n",
            "res4v_branch2b         (Conv2D)\n",
            "bn4v_branch2b          (BatchNorm)\n",
            "res4v_branch2c         (Conv2D)\n",
            "bn4v_branch2c          (BatchNorm)\n",
            "res4w_branch2a         (Conv2D)\n",
            "bn4w_branch2a          (BatchNorm)\n",
            "res4w_branch2b         (Conv2D)\n",
            "bn4w_branch2b          (BatchNorm)\n",
            "res4w_branch2c         (Conv2D)\n",
            "bn4w_branch2c          (BatchNorm)\n",
            "res5a_branch2a         (Conv2D)\n",
            "bn5a_branch2a          (BatchNorm)\n",
            "res5a_branch2b         (Conv2D)\n",
            "bn5a_branch2b          (BatchNorm)\n",
            "res5a_branch2c         (Conv2D)\n",
            "res5a_branch1          (Conv2D)\n",
            "bn5a_branch2c          (BatchNorm)\n",
            "bn5a_branch1           (BatchNorm)\n",
            "res5b_branch2a         (Conv2D)\n",
            "bn5b_branch2a          (BatchNorm)\n",
            "res5b_branch2b         (Conv2D)\n",
            "bn5b_branch2b          (BatchNorm)\n",
            "res5b_branch2c         (Conv2D)\n",
            "bn5b_branch2c          (BatchNorm)\n",
            "res5c_branch2a         (Conv2D)\n",
            "bn5c_branch2a          (BatchNorm)\n",
            "res5c_branch2b         (Conv2D)\n",
            "bn5c_branch2b          (BatchNorm)\n",
            "res5c_branch2c         (Conv2D)\n",
            "bn5c_branch2c          (BatchNorm)\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "In model:  rpn_model\n",
            "    rpn_conv_shared        (Conv2D)\n",
            "    rpn_class_raw          (Conv2D)\n",
            "    rpn_bbox_pred          (Conv2D)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:98: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:2087: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 52/70\n",
            "  9/100 [=>............................] - ETA: 13:25 - loss: 0.8633 - rpn_class_loss: 0.0365 - rpn_bbox_loss: 0.3351 - mrcnn_class_loss: 0.1371 - mrcnn_bbox_loss: 0.1448 - mrcnn_mask_loss: 0.2098"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ESXDFFNTikNO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Save weights\n",
        "# Typically not needed because callbacks save after every epoch\n",
        "# Uncomment to save manually\n",
        "model_path = os.path.join(MODEL_DIR, \"mask_rcnn_shapes.h5\")\n",
        "model.keras_model.save_weights(model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "crfmuM0BiVGr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f86ea0ba-632e-44e0-ac4f-4445bcf71c1e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522794615166,
          "user_tz": 300,
          "elapsed": 13490,
          "user": {
            "displayName": "Chen Zeng",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "104203797268465593050"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Detection\n",
        "class InferenceConfig(KaggleConfig):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "inference_config = InferenceConfig()\n",
        "\n",
        "# Recreate the model in inference mode\n",
        "model = modellib.MaskRCNN(mode=\"inference\", \n",
        "                          config=inference_config,\n",
        "                          model_dir=MODEL_DIR)\n",
        "\n",
        "# Get path to saved weights\n",
        "# Either set a specific path or find last trained weights\n",
        "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
        "model_path = model.find_last()[1]\n",
        "\n",
        "# Load trained weights (fill in path to trained weights here)\n",
        "assert model_path != \"\", \"Provide path to trained weights\"\n",
        "print(\"Loading weights from \", model_path)\n",
        "model.load_weights(model_path, by_name=True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading weights from  /content/logs/shapes20180403T1519/mask_rcnn_shapes_0050.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GQosj2BUtEaF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# # Test on a random image\n",
        "# image_id = random.choice(dataset_val.image_ids)\n",
        "\n",
        "# original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "#     modellib.load_image_gt(dataset_val, inference_config, \n",
        "#                            image_id, use_mini_mask=False)\n",
        "\n",
        "# # Ground truth\n",
        "# log(\"original_image\", original_image)\n",
        "# log(\"image_meta\", image_meta)\n",
        "# log(\"gt_class_id\", gt_class_id)\n",
        "# log(\"gt_bbox\", gt_bbox)\n",
        "# log(\"gt_mask\", gt_mask)\n",
        "\n",
        "# visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
        "#                             dataset_train.class_names, figsize=(8, 8))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dkpUC7GttEaH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# results = model.detect([original_image], verbose=1)\n",
        "\n",
        "# r = results[0]\n",
        "# visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
        "#                             dataset_val.class_names, r['scores'], ax=get_ax())\n",
        "\n",
        "# # r['masks'].shape = 256*256*num\n",
        "# # plt.imshow(r['masks'][:,:,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yeV7kclMtEaK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# # Compute VOC-Style mAP @ IoU=0.5\n",
        "# # Running on 10 images. Increase for better accuracy.\n",
        "# image_ids = np.random.choice(dataset_val.image_ids, 10)\n",
        "# APs = []\n",
        "# for image_id in image_ids:\n",
        "#     # Load image and ground truth data\n",
        "#     image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "#         modellib.load_image_gt(dataset_val, inference_config,\n",
        "#                                image_id, use_mini_mask=False)\n",
        "#     molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
        "#     # Run object detection\n",
        "#     results = model.detect([image], verbose=0)\n",
        "#     r = results[0]\n",
        "#     # Compute AP\n",
        "#     AP, precisions, recalls, overlaps =\\\n",
        "#         utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
        "#                          r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
        "#     APs.append(AP)\n",
        "    \n",
        "# print(\"mAP: \", np.mean(APs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tj5y4Bps8Ptj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# # rle method-1\n",
        "# # Run-length encoding stolen from https://www.kaggle.com/rakhlin/fast-run-length-encoding-python\n",
        "# def rle_encoding(x):\n",
        "#     dots = np.where(x.T.flatten() == 1)[0]\n",
        "#     run_lengths = []\n",
        "#     prev = -2\n",
        "#     for b in dots:\n",
        "#         if (b>prev+1): run_lengths.extend((b + 1, 0))\n",
        "#         run_lengths[-1] += 1\n",
        "#         prev = b\n",
        "#     return run_lengths\n",
        "\n",
        "# def prob_to_rles(x, cutoff=0.5):\n",
        "#     lab_img = label(x > cutoff)\n",
        "#     for i in range(1, lab_img.max() + 1):\n",
        "#         yield rle_encoding(lab_img == i)\n",
        "        \n",
        "# # Iterate over the test IDs and generate run-length encodings for each seperate mask identified by skimage\n",
        "# def mask_to_rle(img_id, mask, test_ids, rles):\n",
        "#     rle = list(prob_to_rles(mask))\n",
        "#     rles.extend(rle)\n",
        "#     test_ids.extend([img_id] * len(rle))\n",
        "#     return test_ids,rles"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4uU0jSq8tEaQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# test_ids = []\n",
        "# rles = []\n",
        "\n",
        "# for image_id in dataset_test.image_ids:\n",
        "#     img_id = dataset_test.img_ids[image_id]\n",
        "#     image = dataset_test.load_image(image_id)\n",
        "#     molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
        "#     # Run object detection\n",
        "#     results = model.detect([image], verbose=0)\n",
        "#     r = results[0]\n",
        "#     mask = r['masks'].max(axis=2)\n",
        "#     test_ids, rles = mask_to_rle(img_id, mask, test_ids, rles)\n",
        "\n",
        "# saved_file = 'rcnn-1.csv'    \n",
        "\n",
        "# print (len(list(set(test_ids))))\n",
        "\n",
        "# # Create submission DataFrame\n",
        "# sub = pd.DataFrame()\n",
        "# sub['ImageId'] = test_ids\n",
        "# sub['EncodedPixels'] = pd.Series(rles).apply(lambda x: ' '.join(str(y) for y in x))\n",
        "# sub.to_csv(saved_file, index=False)\n",
        "\n",
        "# # Install the PyDrive wrapper & import libraries.\n",
        "# # This only needs to be done once in a notebook.\n",
        "# !pip install -U -q PyDrive\n",
        "# from pydrive.auth import GoogleAuth\n",
        "# from pydrive.drive import GoogleDrive\n",
        "# from google.colab import auth\n",
        "# from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# # Authenticate and create the PyDrive client.\n",
        "# # This only needs to be done once in a notebook.\n",
        "# auth.authenticate_user()\n",
        "# gauth = GoogleAuth()\n",
        "# gauth.credentials = GoogleCredentials.get_application_default()\n",
        "# drive = GoogleDrive(gauth)\n",
        "\n",
        "# # Create & upload a file.\n",
        "# uploaded = drive.CreateFile({'title': saved_file})\n",
        "# uploaded.SetContentFile(saved_file)\n",
        "# uploaded.Upload()\n",
        "# print('Uploaded file with ID {}'.format(uploaded.get('id')))\n",
        "# # 4/AACG6-C0U8VukJ2_YnpV2e6QZ59968sOM1sdmryFRHG8oWfN3oS9DDE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eFNidQPd7Vbu",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# rle method-2\n",
        "def numpy2encoding_no_overlap2(predicts, img_id):\n",
        "    sum_predicts = np.sum(predicts, axis=2)\n",
        "    rows, cols = np.where(sum_predicts>=2)\n",
        "    \n",
        "    for i in zip(rows, cols):\n",
        "        instance_indicies = np.where(np.any(predicts[i[0],i[1],:]))[0]\n",
        "        highest = instance_indicies[0]\n",
        "        predicts[i[0],i[1],:] = predicts[i[0],i[1],:]*0\n",
        "        predicts[i[0],i[1],highest] = 1\n",
        "    \n",
        "    ImageId = []\n",
        "    EncodedPixels = []\n",
        "    for i in range(predicts.shape[2]): \n",
        "        rle = run_length_encoding(predicts[:,:,i])\n",
        "        if len(rle)>0:\n",
        "            ImageId.append(img_id)\n",
        "            EncodedPixels.append(rle)    \n",
        "    return ImageId, EncodedPixels\n",
        "\n",
        "def run_length_encoding(x):\n",
        "    dots = np.where(x.T.flatten() == 1)[0]\n",
        "    run_lengths = []\n",
        "    prev = -2\n",
        "    for b in dots:\n",
        "        if (b>prev+1): run_lengths.extend((b + 1, 0))\n",
        "        run_lengths[-1] += 1\n",
        "        prev = b\n",
        "    run_lengths = ' '.join([str(r) for r in run_lengths])\n",
        "    return run_lengths"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a3-GcgAC7Wm6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "ImageId = []\n",
        "EncodedPixels = []\n",
        "\n",
        "for image_id in dataset_test.image_ids:\n",
        "    img_id = dataset_test.img_ids[image_id]\n",
        "    image = dataset_test.load_image(image_id)\n",
        "    results = model.detect([image], verbose=0)\n",
        "    r = results[0]\n",
        "#     idx = utils.non_max_suppression(r['rois'], r['scores'], 0.2)\n",
        "#     ImageId_batch, EncodedPixels_batch = numpy2encoding_no_overlap2(r['masks'][idx], img_id)\n",
        "    ImageId_batch, EncodedPixels_batch = numpy2encoding_no_overlap2(r['masks'], img_id)\n",
        "    ImageId += ImageId_batch\n",
        "    EncodedPixels += EncodedPixels_batch\n",
        "    \n",
        "saved_file = 'rcnn-6.csv'\n",
        "\n",
        "# Create submission DataFrame\n",
        "sub = pd.DataFrame()\n",
        "sub['ImageId'] = ImageId\n",
        "# sub['EncodedPixels'] = pd.Series(EncodedPixels).apply(lambda x: ''.join(str(y) for y in x))\n",
        "sub['EncodedPixels'] = EncodedPixels\n",
        "sub.to_csv(saved_file, index=False)\n",
        "\n",
        "# # Install the PyDrive wrapper & import libraries.\n",
        "# # This only needs to be done once in a notebook.\n",
        "# !pip install -U -q PyDrive\n",
        "# from pydrive.auth import GoogleAuth\n",
        "# from pydrive.drive import GoogleDrive\n",
        "# from google.colab import auth\n",
        "# from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# # Authenticate and create the PyDrive client.\n",
        "# # This only needs to be done once in a notebook.\n",
        "# auth.authenticate_user()\n",
        "# gauth = GoogleAuth()\n",
        "# gauth.credentials = GoogleCredentials.get_application_default()\n",
        "# drive = GoogleDrive(gauth)\n",
        "\n",
        "# # Create & upload a file.\n",
        "# uploaded = drive.CreateFile({'title': saved_file})\n",
        "# uploaded.SetContentFile(saved_file)\n",
        "# uploaded.Upload()\n",
        "# print('Uploaded file with ID {}'.format(uploaded.get('id')))\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.download(saved_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uW0WMPaidMGX",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ceba5244-53a8-4e5c-9d29-3bf76505b1bc",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522794909710,
          "user_tz": 300,
          "elapsed": 4749,
          "user": {
            "displayName": "Chen Zeng",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "104203797268465593050"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Save the model to Google Drive\n",
        "!ls\n",
        "\n",
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once in a notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once in a notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "saved_file = 'mask_rcnn_coco.h5'\n",
        "\n",
        "# Create & upload a file.\n",
        "uploaded = drive.CreateFile({'title': saved_file})\n",
        "uploaded.SetContentFile(saved_file)\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))\n",
        "\n",
        "# saved_file = 'mask_rcnn_coco.h5'\n",
        "# files.download(saved_file)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded file with ID 1OXCGxu3Gzcv6zWsIpdi22hJZ1DUg3Ibz\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}